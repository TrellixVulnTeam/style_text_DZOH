{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 1.,  2.,  3.]), tensor([ 4.,  5.]), tensor([ 6.])]\n",
      "tensor([[ 1.,  4.,  6.],\n",
      "        [ 2.,  5.,  0.],\n",
      "        [ 3.,  0.,  0.]])\n",
      "PackedSequence(data=tensor([ 1.,  4.,  6.,  2.,  5.,  3.]), batch_sizes=tensor([ 3,  2,  1]))\n",
      "tensor([[ 1.,  4.,  6.],\n",
      "        [ 2.,  5.,  0.],\n",
      "        [ 3.,  0.,  0.]])\n",
      "PackedSequence(data=tensor([ 1.,  4.,  6.,  2.,  5.,  3.]), batch_sizes=tensor([ 3,  2,  1]))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils\n",
    "# %% packed sequences\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([4, 5])\n",
    "c = torch.Tensor([6])\n",
    "lengths = list(map(len, [a, b, c]))\n",
    "padded= torch.nn.utils.rnn.pad_sequence([a, b, c], batch_first=False)\n",
    "packed_padded =torch.nn.utils.rnn.pack_padded_sequence(padded, lengths) # non ho messo batch first da qui in poi\n",
    "repadded = torch.nn.utils.rnn.pad_packed_sequence(packed_padded)[0]\n",
    "repacked = torch.nn.utils.rnn.pack_padded_sequence(repadded, lengths)\n",
    "print([a, b, c])\n",
    "print(padded)\n",
    "print(packed_padded)\n",
    "print(repadded)\n",
    "print(repacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parameters import Params\n",
    "from src.vocabulary import Vocabulary\n",
    "from src.style_transfer import StyleTransfer\n",
    "from src.greedy_decoding import Decoder\n",
    "from src.generate_batches import preprocessSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "vocab = Vocabulary()\n",
    "vocab.loadVocabulary(\"data/yelp/vocabulary.pickle\")\n",
    "vocab.initializeEmbeddings(params.embedding_size)\n",
    "model = StyleTransfer(params, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load(\"data/models/yelp/model-2018-06-27-epoch_18-loss_45.287033\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('data/yelp/dev/negative.txt', 'r') as fp:\n",
    "    testSents = fp.readlines()[:16]\n",
    "    \n",
    "labels = np.array([0] * len(testSents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(model, 20, 12, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs, generator_inputs, targets, lenghts = \\\n",
    "            model._sentencesToInputs(testSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval_size = 16\n",
    "model._computeHiddens(\n",
    "                encoder_inputs, generator_inputs, labels, lenghts, True)\n",
    "generatorOutputs, h_teacher = model._generateTokens(\n",
    "            generator_inputs, model.originalHiddens, lenghts, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3259, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packedGenOutput = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "    generatorOutputs, lenghts, batch_first = False)[0] # PROVA CON batch_first = True, sballa l'ordine!\n",
    "\n",
    "model.rec_loss_criterion(\n",
    "    packedGenOutput.view(-1, model.vocabulary.vocabSize),\n",
    "    targets.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was obvious it was the same damn he he brought the first class ! .',\n",
       " 'easter day nothing open , heard about this place figured it was topped <eos> <eos>',\n",
       " 'the host that walked us to the table and left without a word warm shot',\n",
       " 'the last couple years this place has been going down hill away .',\n",
       " 'last night however it was way to thick and tasteless garlic !',\n",
       " 'i tried to eat it but it was disgusting shopping chewy',\n",
       " \"i pushed it aside and did n't eat anymore outside hell\",\n",
       " 'ok never going back to this place again repair .',\n",
       " 'no sign of the manager thanks .',\n",
       " 'it smelled like rotten urine family .',\n",
       " 'i will never be back shopping .',\n",
       " 'it just gets worse of .',\n",
       " 'the food tasted awful . .',\n",
       " 'i am not exaggerating in .',\n",
       " 'this bad bad . .',\n",
       " 'it tasted horrible in .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(16):\n",
    "    tokensLogits = generatorOutputs[index, :, :]\n",
    "    sent = []\n",
    "    len = lenghts[index]\n",
    "    for j in range(len):\n",
    "        logit = tokensLogits[j, :]\n",
    "        sent.append(model.vocabulary.id2word[logit.argmax()])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 9603])\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "print(packedGenOutput.shape)\n",
    "print(targets.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'was',\n",
       " 'obvious',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'same',\n",
       " 'damn',\n",
       " 'he',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'the',\n",
       " 'first',\n",
       " 'class',\n",
       " '!',\n",
       " '.',\n",
       " 'easter',\n",
       " 'day',\n",
       " 'nothing',\n",
       " 'open',\n",
       " ',',\n",
       " 'heard',\n",
       " 'about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'figured',\n",
       " 'it',\n",
       " 'was',\n",
       " 'topped',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " ')',\n",
       " 'the',\n",
       " 'host',\n",
       " 'that',\n",
       " 'walked',\n",
       " 'us',\n",
       " 'to',\n",
       " 'the',\n",
       " 'table',\n",
       " 'and',\n",
       " 'left',\n",
       " 'without',\n",
       " 'a',\n",
       " 'word',\n",
       " 'warm',\n",
       " 'shot',\n",
       " ')',\n",
       " 'the',\n",
       " 'last',\n",
       " 'couple',\n",
       " 'years',\n",
       " 'this',\n",
       " 'place',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'down',\n",
       " 'hill',\n",
       " 'away',\n",
       " '.',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " 'last',\n",
       " 'night',\n",
       " 'however',\n",
       " 'it',\n",
       " 'was',\n",
       " 'way',\n",
       " 'to',\n",
       " 'thick',\n",
       " 'and',\n",
       " 'tasteless',\n",
       " 'garlic',\n",
       " '!',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " 'i',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'it',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'shopping',\n",
       " 'chewy',\n",
       " ')',\n",
       " ')',\n",
       " ')',\n",
       " 'i',\n",
       " 'pushed',\n",
       " 'it',\n",
       " 'aside',\n",
       " 'and',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'anymore',\n",
       " 'outside',\n",
       " 'hell',\n",
       " 'ok',\n",
       " 'never',\n",
       " 'going',\n",
       " 'back',\n",
       " 'to',\n",
       " 'this',\n",
       " 'place',\n",
       " 'again',\n",
       " 'no',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'the',\n",
       " 'manager',\n",
       " 'thanks',\n",
       " '.',\n",
       " ')',\n",
       " 'it',\n",
       " 'smelled',\n",
       " 'like',\n",
       " 'rotten',\n",
       " 'urine',\n",
       " 'family',\n",
       " '.',\n",
       " ')',\n",
       " 'i',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'back',\n",
       " 'shopping',\n",
       " '.',\n",
       " 'it',\n",
       " 'just',\n",
       " 'gets',\n",
       " 'worse',\n",
       " 'of',\n",
       " 'the',\n",
       " 'food',\n",
       " 'tasted',\n",
       " 'awful',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'this',\n",
       " 'bad',\n",
       " 'bad',\n",
       " 'it']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(packedGenOutput.shape[0]):\n",
    "    tokensLogits = packedGenOutput[index]\n",
    "    sent = []\n",
    "    sent.append(model.vocabulary.id2word[tokensLogits.argmax()])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'was',\n",
       " 'obvious',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'same',\n",
       " 'damn',\n",
       " 'one',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " 'easter',\n",
       " 'day',\n",
       " 'nothing',\n",
       " 'open',\n",
       " ',',\n",
       " 'heard',\n",
       " 'about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'figured',\n",
       " 'it',\n",
       " 'would',\n",
       " 'ok',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " 'the',\n",
       " 'host',\n",
       " 'that',\n",
       " 'walked',\n",
       " 'us',\n",
       " 'to',\n",
       " 'the',\n",
       " 'table',\n",
       " 'and',\n",
       " 'left',\n",
       " 'without',\n",
       " 'a',\n",
       " 'word',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " 'the',\n",
       " 'last',\n",
       " 'couple',\n",
       " 'years',\n",
       " 'this',\n",
       " 'place',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'down',\n",
       " 'hill',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'last',\n",
       " 'night',\n",
       " 'however',\n",
       " 'it',\n",
       " 'was',\n",
       " 'way',\n",
       " 'to',\n",
       " 'thick',\n",
       " 'and',\n",
       " 'tasteless',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'i',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'it',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " 'i',\n",
       " 'pushed',\n",
       " 'it',\n",
       " 'aside',\n",
       " 'and',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'anymore',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " 'ok',\n",
       " 'never',\n",
       " 'going',\n",
       " 'back',\n",
       " 'to',\n",
       " 'this',\n",
       " 'place',\n",
       " 'again',\n",
       " 'no',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'the',\n",
       " 'manager',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " 'it',\n",
       " 'smelled',\n",
       " 'like',\n",
       " 'rotten',\n",
       " 'urine',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " 'i',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'back',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " 'it',\n",
       " 'just',\n",
       " 'gets',\n",
       " 'worse',\n",
       " '<unk>',\n",
       " 'the',\n",
       " 'food',\n",
       " 'tasted',\n",
       " 'awful',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'this',\n",
       " 'smelled',\n",
       " 'bad',\n",
       " 'it']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(targets.shape[0]):\n",
    "    word = targets[index]\n",
    "    sent = []\n",
    "    sent.append(model.vocabulary.id2word[word])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok never going back to this place again .\\n',\n",
       " 'easter day nothing open , heard about this place figured it would ok .\\n',\n",
       " 'the host that walked us to the table and left without a word .\\n',\n",
       " 'it just gets worse .\\n',\n",
       " 'the food tasted awful .\\n',\n",
       " 'no sign of the manager .\\n',\n",
       " 'the last couple years this place has been going down hill .\\n',\n",
       " 'last night however it was way to thick and tasteless .\\n',\n",
       " 'it smelled like rotten urine .\\n',\n",
       " 'i am not exaggerating .\\n',\n",
       " 'this smelled bad !\\n',\n",
       " 'it was obvious it was the same damn one he brought the first time .\\n',\n",
       " 'i tried to eat it but it was disgusting .\\n',\n",
       " 'it tasted horrible !\\n',\n",
       " \"i pushed it aside and did n't eat anymore .\\n\",\n",
       " 'i will never be back .\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   14,  4569,     5,     5,   262,     7,     7,   302,    56,\n",
       "           14,     7,    14,     5,     7,    15,    14,    11,   222,\n",
       "         1818,   262,   205,   324,  3793,    98,   888,  1081,    51,\n",
       "           57,    17,   177,  1081,   291,  2254,   168,    36,   674,\n",
       "          288,    13,    14,   127,    22,    71,    98,   510,   291,\n",
       "           28,   107,   125,    14,   449,   337,   265,    14,   169,\n",
       "         2135,    53,     5,  2865,    48,   421,   308,  3925,     3,\n",
       "            3,    11,     9,   134,    15,    11,    14,     6,    13,\n",
       "          328,  3916,    53,     3,     3,     3,     2,     2,     5,\n",
       "         1347,    13,    19,   167,    40,    75,    15,     3,     3,\n",
       "            3,     2,     2,     2,   367,   106,     5,    83,    13,\n",
       "           14,    31,    19,     2,     2,     2,   986,    15,   399,\n",
       "           86,  1266,    11,   169,    89,    67,    19,     6,   127,\n",
       "            6,   435,   934,     3,    87,  2410,   263,   194,   785,\n",
       "            3,     3,     2,   566,    14,   519,  1527,     3,     2,\n",
       "            2,     5,    65,    12,     3,     2,   143,   302,  1083,\n",
       "            2,    64,     3,     3,     3,     2,     2,     2], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, tsf = decoder.rewriteBatch(testSents[:2], labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(torch.FloatTensor([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'the restaurant was nice but food tasted ugly'.split()\n",
    "h = torch.zeros(700).to('cuda')\n",
    "h = h.unsqueeze(0).unsqueeze(0)\n",
    "for token in sent:\n",
    "    emb = vocab([token])\n",
    "    emb = emb.unsqueeze(1)\n",
    "    out, h = model.generator(emb, h, pad=False)\n",
    "    voc = model.hiddenToVocab(out)\n",
    "    _, id = voc.max(2)\n",
    "    h = h\n",
    "    print(vocab.id2word[int(id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hiddenToVocab(out).max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
