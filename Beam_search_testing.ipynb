{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 1.,  2.,  3.]), tensor([ 4.,  5.]), tensor([ 6.])]\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  0.],\n",
      "        [ 6.,  0.,  0.]])\n",
      "PackedSequence(data=tensor([ 1.,  2.,  3.,  4.,  5.,  6.]), batch_sizes=tensor([ 3,  2,  1]))\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  0.],\n",
      "        [ 6.,  0.,  0.]])\n",
      "PackedSequence(data=tensor([ 1.,  2.,  3.,  4.,  5.,  6.]), batch_sizes=tensor([ 3,  2,  1]))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils\n",
    "# %% packed sequences\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([4, 5])\n",
    "c = torch.Tensor([6])\n",
    "lengths = list(map(len, [a, b, c]))\n",
    "padded= torch.nn.utils.rnn.pad_sequence([a, b, c], batch_first=True)\n",
    "packed_padded =torch.nn.utils.rnn.pack_padded_sequence(padded, lengths) # non ho messo batch first da qui in poi\n",
    "repadded = torch.nn.utils.rnn.pad_packed_sequence(packed_padded)[0]\n",
    "repacked = torch.nn.utils.rnn.pack_padded_sequence(repadded, lengths)\n",
    "print([a, b, c])\n",
    "print(padded)\n",
    "print(packed_padded)\n",
    "print(repadded)\n",
    "print(repacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parameters import Params\n",
    "from src.vocabulary import Vocabulary\n",
    "from src.style_transfer import StyleTransfer\n",
    "from src.greedy_decoding import Decoder\n",
    "from src.generate_batches import preprocessSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()\n",
    "vocab = Vocabulary()\n",
    "vocab.loadVocabulary(\"data/yelp/vocabulary.pickle\")\n",
    "vocab.initializeEmbeddings(params.embedding_size)\n",
    "model = StyleTransfer(params, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load(\"data/models/yelp/model-2018-06-26-epoch_19-loss_68.143707\")\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('data/yelp/dev/negative.txt', 'r') as fp:\n",
    "    testSents = fp.readlines()[:16]\n",
    "    \n",
    "labels = np.array([0] * len(testSents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(model, 20, 12, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs, generator_inputs, targets, lenghts = \\\n",
    "            model._sentencesToInputs(testSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval_size = 16\n",
    "model._computeHiddens(\n",
    "                encoder_inputs, generator_inputs, labels, lenghts, True)\n",
    "generatorOutputs, h_teacher = model._generateTokens(\n",
    "            generator_inputs, model.originalHiddens, lenghts, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.5104, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packedGenOutput = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "    generatorOutputs, lenghts)[0] # PROVA CON batch_first = True, sballa l'ordine!\n",
    "\n",
    "model.rec_loss_criterion(\n",
    "    packedGenOutput.view(-1, model.vocabulary.vocabSize),\n",
    "    targets.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was obvious it was the same damn one he brought the first time . .',\n",
       " 'major day nothing open , heard about this place figured it ok ok . .',\n",
       " 'the host that walked us to the table and left without to word hello .',\n",
       " 'the last couple years this place has been going smoothly hill to detailing',\n",
       " 'last night however it was way to thick and tasteless power !',\n",
       " 'i tried to eat it but it was disgusting appropriately !',\n",
       " \"i pushed it by and did n't eat anymore than the\",\n",
       " 'ok never going back to this place again to !',\n",
       " 'no sign of the manager ! !',\n",
       " 'it smelled like rotten pretentious . .',\n",
       " 'i will never be back . .',\n",
       " 'it just gets worse . .',\n",
       " 'the food tasted awful . .',\n",
       " 'i am not exaggerating madison !',\n",
       " 'this smelled bad yourself .',\n",
       " 'it tasted horrible neighborhood word']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(16):\n",
    "    tokensLogits = generatorOutputs[index, :, :]\n",
    "    sent = []\n",
    "    len = lenghts[index]\n",
    "    for j in range(len):\n",
    "        logit = tokensLogits[j, :]\n",
    "        sent.append(model.vocabulary.id2word[logit.argmax()])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([152, 9603])\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "print(packedGenOutput.shape)\n",
    "print(targets.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   14,  4569,     5,     5,   262,     7,     7,   302,    56,\n",
       "           14,     7,    14,     5,     7,    15,    14,    11,   222,\n",
       "         1818,   262,   205,   324,  3793,    98,   888,  1081,    51,\n",
       "           57,    17,   177,  1081,   291,  2254,   168,    36,   674,\n",
       "          288,    13,    14,   127,    22,    71,    98,   510,   291,\n",
       "           28,   107,   125,    14,   449,   337,   265,    14,   169,\n",
       "         2135,    53,     5,  2865,    48,   421,   308,  3925,     3,\n",
       "            3,    11,     9,   134,    15,    11,    14,     6,    13,\n",
       "          328,  3916,    53,     3,     3,     3,     2,     2,     5,\n",
       "         1347,    13,    19,   167,    40,    75,    15,     3,     3,\n",
       "            3,     2,     2,     2,   367,   106,     5,    83,    13,\n",
       "           14,    31,    19,     2,     2,     2,   986,    15,   399,\n",
       "           86,  1266,    11,   169,    89,    67,    19,     6,   127,\n",
       "            6,   435,   934,     3,    87,  2410,   263,   194,   785,\n",
       "            3,     3,     2,   566,    14,   519,  1527,     3,     2,\n",
       "            2,     5,    65,    12,     3,     2,   143,   302,  1083,\n",
       "            2,    64,     3,     3,     3,     2,     2,     2], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'was',\n",
       " 'obvious',\n",
       " 'it',\n",
       " 'was',\n",
       " 'the',\n",
       " 'same',\n",
       " 'damn',\n",
       " 'one',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " '.',\n",
       " '.',\n",
       " 'major',\n",
       " 'day',\n",
       " 'nothing',\n",
       " 'open',\n",
       " ',',\n",
       " 'heard',\n",
       " 'about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'figured',\n",
       " 'it',\n",
       " 'ok',\n",
       " 'ok',\n",
       " '.',\n",
       " '.',\n",
       " 'the',\n",
       " 'the',\n",
       " 'host',\n",
       " 'that',\n",
       " 'walked',\n",
       " 'us',\n",
       " 'to',\n",
       " 'the',\n",
       " 'table',\n",
       " 'and',\n",
       " 'left',\n",
       " 'without',\n",
       " 'to',\n",
       " 'word',\n",
       " 'hello',\n",
       " '.',\n",
       " 'the',\n",
       " 'the',\n",
       " 'last',\n",
       " 'couple',\n",
       " 'years',\n",
       " 'this',\n",
       " 'place',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'smoothly',\n",
       " 'hill',\n",
       " 'to',\n",
       " 'detailing',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'last',\n",
       " 'night',\n",
       " 'however',\n",
       " 'it',\n",
       " 'was',\n",
       " 'way',\n",
       " 'to',\n",
       " 'thick',\n",
       " 'and',\n",
       " 'tasteless',\n",
       " 'power',\n",
       " '!',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'i',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'eat',\n",
       " 'it',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'disgusting',\n",
       " 'appropriately',\n",
       " '!',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'i',\n",
       " 'pushed',\n",
       " 'it',\n",
       " 'by',\n",
       " 'and',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'eat',\n",
       " 'anymore',\n",
       " 'than',\n",
       " 'the',\n",
       " 'ok',\n",
       " 'never',\n",
       " 'going',\n",
       " 'back',\n",
       " 'to',\n",
       " 'this',\n",
       " 'place',\n",
       " 'again',\n",
       " 'no',\n",
       " 'sign',\n",
       " 'of',\n",
       " 'the',\n",
       " 'manager',\n",
       " '!',\n",
       " '!',\n",
       " 'the',\n",
       " 'it',\n",
       " 'smelled',\n",
       " 'like',\n",
       " 'rotten',\n",
       " 'pretentious',\n",
       " '.',\n",
       " '.',\n",
       " 'the',\n",
       " 'i',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'back',\n",
       " '.',\n",
       " '.',\n",
       " 'it',\n",
       " 'just',\n",
       " 'gets',\n",
       " 'worse',\n",
       " '.',\n",
       " 'the',\n",
       " 'food',\n",
       " 'tasted',\n",
       " 'awful',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'this',\n",
       " 'smelled',\n",
       " 'bad',\n",
       " 'it']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(packedGenOutput.shape[0]):\n",
    "    tokensLogits = packedGenOutput[index]\n",
    "    sent = []\n",
    "    sent.append(model.vocabulary.id2word[tokensLogits.argmax()])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14, device='cuda:0')\n",
      "tensor(4569, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(262, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(302, device='cuda:0')\n",
      "tensor(56, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(222, device='cuda:0')\n",
      "tensor(1818, device='cuda:0')\n",
      "tensor(262, device='cuda:0')\n",
      "tensor(205, device='cuda:0')\n",
      "tensor(324, device='cuda:0')\n",
      "tensor(3793, device='cuda:0')\n",
      "tensor(98, device='cuda:0')\n",
      "tensor(888, device='cuda:0')\n",
      "tensor(1081, device='cuda:0')\n",
      "tensor(51, device='cuda:0')\n",
      "tensor(57, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "tensor(177, device='cuda:0')\n",
      "tensor(1081, device='cuda:0')\n",
      "tensor(291, device='cuda:0')\n",
      "tensor(2254, device='cuda:0')\n",
      "tensor(168, device='cuda:0')\n",
      "tensor(36, device='cuda:0')\n",
      "tensor(674, device='cuda:0')\n",
      "tensor(288, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(127, device='cuda:0')\n",
      "tensor(22, device='cuda:0')\n",
      "tensor(71, device='cuda:0')\n",
      "tensor(98, device='cuda:0')\n",
      "tensor(510, device='cuda:0')\n",
      "tensor(291, device='cuda:0')\n",
      "tensor(28, device='cuda:0')\n",
      "tensor(107, device='cuda:0')\n",
      "tensor(125, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(449, device='cuda:0')\n",
      "tensor(337, device='cuda:0')\n",
      "tensor(265, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(169, device='cuda:0')\n",
      "tensor(2135, device='cuda:0')\n",
      "tensor(53, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(2865, device='cuda:0')\n",
      "tensor(48, device='cuda:0')\n",
      "tensor(421, device='cuda:0')\n",
      "tensor(308, device='cuda:0')\n",
      "tensor(3925, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(134, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(328, device='cuda:0')\n",
      "tensor(3916, device='cuda:0')\n",
      "tensor(53, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(1347, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(167, device='cuda:0')\n",
      "tensor(40, device='cuda:0')\n",
      "tensor(75, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(367, device='cuda:0')\n",
      "tensor(106, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(83, device='cuda:0')\n",
      "tensor(13, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(31, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(986, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(399, device='cuda:0')\n",
      "tensor(86, device='cuda:0')\n",
      "tensor(1266, device='cuda:0')\n",
      "tensor(11, device='cuda:0')\n",
      "tensor(169, device='cuda:0')\n",
      "tensor(89, device='cuda:0')\n",
      "tensor(67, device='cuda:0')\n",
      "tensor(19, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(127, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(435, device='cuda:0')\n",
      "tensor(934, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(87, device='cuda:0')\n",
      "tensor(2410, device='cuda:0')\n",
      "tensor(263, device='cuda:0')\n",
      "tensor(194, device='cuda:0')\n",
      "tensor(785, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(566, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(519, device='cuda:0')\n",
      "tensor(1527, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(5, device='cuda:0')\n",
      "tensor(65, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(143, device='cuda:0')\n",
      "tensor(302, device='cuda:0')\n",
      "tensor(1083, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(64, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'easter',\n",
       " 'the',\n",
       " 'the',\n",
       " 'last',\n",
       " 'i',\n",
       " 'i',\n",
       " 'ok',\n",
       " 'no',\n",
       " 'it',\n",
       " 'i',\n",
       " 'it',\n",
       " 'the',\n",
       " 'i',\n",
       " 'this',\n",
       " 'it',\n",
       " 'was',\n",
       " 'day',\n",
       " 'host',\n",
       " 'last',\n",
       " 'night',\n",
       " 'tried',\n",
       " 'pushed',\n",
       " 'never',\n",
       " 'sign',\n",
       " 'smelled',\n",
       " 'will',\n",
       " 'just',\n",
       " 'food',\n",
       " 'am',\n",
       " 'smelled',\n",
       " 'tasted',\n",
       " 'obvious',\n",
       " 'nothing',\n",
       " 'that',\n",
       " 'couple',\n",
       " 'however',\n",
       " 'to',\n",
       " 'it',\n",
       " 'going',\n",
       " 'of',\n",
       " 'like',\n",
       " 'never',\n",
       " 'gets',\n",
       " 'tasted',\n",
       " 'not',\n",
       " 'bad',\n",
       " 'horrible',\n",
       " 'it',\n",
       " 'open',\n",
       " 'walked',\n",
       " 'years',\n",
       " 'it',\n",
       " 'eat',\n",
       " 'aside',\n",
       " 'back',\n",
       " 'the',\n",
       " 'rotten',\n",
       " 'be',\n",
       " 'worse',\n",
       " 'awful',\n",
       " 'exaggerating',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'was',\n",
       " ',',\n",
       " 'us',\n",
       " 'this',\n",
       " 'was',\n",
       " 'it',\n",
       " 'and',\n",
       " 'to',\n",
       " 'manager',\n",
       " 'urine',\n",
       " 'back',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " 'the',\n",
       " 'heard',\n",
       " 'to',\n",
       " 'place',\n",
       " 'way',\n",
       " 'but',\n",
       " 'did',\n",
       " 'this',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " 'same',\n",
       " 'about',\n",
       " 'the',\n",
       " 'has',\n",
       " 'to',\n",
       " 'it',\n",
       " \"n't\",\n",
       " 'place',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " 'damn',\n",
       " 'this',\n",
       " 'table',\n",
       " 'been',\n",
       " 'thick',\n",
       " 'was',\n",
       " 'eat',\n",
       " 'again',\n",
       " 'one',\n",
       " 'place',\n",
       " 'and',\n",
       " 'going',\n",
       " 'and',\n",
       " 'disgusting',\n",
       " 'anymore',\n",
       " '<unk>',\n",
       " 'he',\n",
       " 'figured',\n",
       " 'left',\n",
       " 'down',\n",
       " 'tasteless',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " 'brought',\n",
       " 'it',\n",
       " 'without',\n",
       " 'hill',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " 'the',\n",
       " 'would',\n",
       " 'a',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " 'first',\n",
       " 'ok',\n",
       " 'word',\n",
       " '<eos>',\n",
       " 'time',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '<eos>',\n",
       " '<eos>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = []\n",
    "for index in range(targets.shape[0]):\n",
    "    word = targets[index]\n",
    "    sent = []\n",
    "    print(word)\n",
    "    sent.append(model.vocabulary.id2word[word])\n",
    "    sents.append(\" \".join(sent))\n",
    "sents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok never going back to this place again .\\n',\n",
       " 'easter day nothing open , heard about this place figured it would ok .\\n',\n",
       " 'the host that walked us to the table and left without a word .\\n',\n",
       " 'it just gets worse .\\n',\n",
       " 'the food tasted awful .\\n',\n",
       " 'no sign of the manager .\\n',\n",
       " 'the last couple years this place has been going down hill .\\n',\n",
       " 'last night however it was way to thick and tasteless .\\n',\n",
       " 'it smelled like rotten urine .\\n',\n",
       " 'i am not exaggerating .\\n',\n",
       " 'this smelled bad !\\n',\n",
       " 'it was obvious it was the same damn one he brought the first time .\\n',\n",
       " 'i tried to eat it but it was disgusting .\\n',\n",
       " 'it tasted horrible !\\n',\n",
       " \"i pushed it aside and did n't eat anymore .\\n\",\n",
       " 'i will never be back .\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   14,  4569,     5,     5,   262,     7,     7,   302,    56,\n",
       "           14,     7,    14,     5,     7,    15,    14,    11,   222,\n",
       "         1818,   262,   205,   324,  3793,    98,   888,  1081,    51,\n",
       "           57,    17,   177,  1081,   291,  2254,   168,    36,   674,\n",
       "          288,    13,    14,   127,    22,    71,    98,   510,   291,\n",
       "           28,   107,   125,    14,   449,   337,   265,    14,   169,\n",
       "         2135,    53,     5,  2865,    48,   421,   308,  3925,     3,\n",
       "            3,    11,     9,   134,    15,    11,    14,     6,    13,\n",
       "          328,  3916,    53,     3,     3,     3,     2,     2,     5,\n",
       "         1347,    13,    19,   167,    40,    75,    15,     3,     3,\n",
       "            3,     2,     2,     2,   367,   106,     5,    83,    13,\n",
       "           14,    31,    19,     2,     2,     2,   986,    15,   399,\n",
       "           86,  1266,    11,   169,    89,    67,    19,     6,   127,\n",
       "            6,   435,   934,     3,    87,  2410,   263,   194,   785,\n",
       "            3,     3,     2,   566,    14,   519,  1527,     3,     2,\n",
       "            2,     5,    65,    12,     3,     2,   143,   302,  1083,\n",
       "            2,    64,     3,     3,     3,     2,     2,     2], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, tsf = decoder.rewriteBatch(testSents[:2], labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(torch.FloatTensor([1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'the restaurant was nice but food tasted ugly'.split()\n",
    "h = torch.zeros(700).to('cuda')\n",
    "h = h.unsqueeze(0).unsqueeze(0)\n",
    "for token in sent:\n",
    "    emb = vocab([token])\n",
    "    emb = emb.unsqueeze(1)\n",
    "    out, h = model.generator(emb, h, pad=False)\n",
    "    voc = model.hiddenToVocab(out)\n",
    "    _, id = voc.max(2)\n",
    "    h = h\n",
    "    print(vocab.id2word[int(id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hiddenToVocab(out).max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
